---
title: "Model Interrogation"
author:
- Stephen E. Lane
---

<!-- Time-stamp: <2017-10-12 04:37:52 (overlordR)> -->

```{r setup,echo=FALSE,warning=FALSE,message=FALSE,cache=FALSE,results="hide"}
knitr::opts_chunk$set(error = FALSE, warning = FALSE, cache = FALSE,
                      message = FALSE, echo = FALSE,
                      cache.path = "interrogate-cache/",
                      fig.path = "html-figures/")
options(digits = 2, width = 100)

```

```{r packages}
## Add github packages using gitname/reponame format
source("../scripts/imputation-functions.R")
packages <- c("dplyr", "tidyr", "ggplot2", "rstan", "loo")
ipak(packages)
options(mc.cores = round(parallel::detectCores()/2))

```

# Introduction

In this document, I detail the model interrogation for the *blistering barnacles* (otherwise known as *biofouling*) project. For the introduction and set up of the problem, see the [manuscript](file:../manuscripts/censored-mle.pdf). This document expands upon the modelling description as given in that paper.

# Models

The basic model (which we denote M0) included the location of the measurement as a level one fixed effect, and a modelled intercept for the vessel ID. We investigate two different models for the regression error:

$$
\begin{align}
  \log Y_{i} & \sim \text{Normal}(\mu_{i}, \sigma) \\
  \log Y_{i} & \sim t_{\nu}(\mu_{i}, \sigma)
\end{align}
$$

The $t$ distributed model allows us to have a little more robustness, and our expectation is that this model will perform the best. The specification for model M0 is completed with the following:

$$
\begin{align}
  \nu & \sim \text{Gamma}(2, 0.1) \\
  \mu_{i} & = \mu + \alpha_{j[i]} + \beta_{l[i]} \\
  \mu & \sim N(0, 5) \\
  \alpha_{j} & \sim \text{cauchy}(0, \sigma_{\alpha}) \\
  \beta_{l} & \sim t_{3}(0, \sigma_{l}) \\
  \sigma,\sigma_{\alpha} & \sim \text{cauchy}(0, 2.5)
\end{align}
$$

where $j$ references vessels, and $l$ references locations. Thus, $\alpha_{j}$ and $\beta_{l}$ are the variation around the mean due to the location of measurement and particular vessel respectively. Summary output from this model follows.

## M0

### M0 &mdash; Normal distribution

```{r m0N,cache=TRUE}
m0N <- readRDS("../data/censored-mle-m0-var-bayes.rds")
m0Nll <- extract_log_lik(m0N)
m0Nloo <- loo::loo(m0Nll)
print(m0N, digits = 2, include = FALSE,
      par = c("alphaBoat", "muHat", "muHatCens", "log_lik", "alphaHat",
              "y_ppc", "y_lower"))

```

### M0 &mdash; $t$ distribution

```{r m0,cache=TRUE}
m0 <- readRDS("../data/censored-mle-m0-t-var-bayes.rds")
m0ll <- extract_log_lik(m0)
m0loo <- loo::loo(m0ll)
print(m0, digits = 2, include = FALSE,
      par = c("alphaBoat", "muHat", "muHatCens", "log_lik", "alphaHat",
              "y_ppc", "y_lower"))

```

### Comparison between Normal and $t$ assumptions

We now compare the two base models based on their predictive log-likelihoods:

```{r compare-m0}
compare(m0Nloo, m0loo)

```

So in the M0 models, there's not a huge difference in predictive log-likelihood between the Normal and $t$ distribution regressions.

### Posterior predictive checks

```{r post-pred-m0,cache=TRUE}
yPPC <- extract(m0, "y_ppc")$y_ppc
yPPCExp <- exp(yPPC)
ppc1 <- rowMeans(yPPC < log(1.5))
ppc2 <- apply(yPPCExp, 1, quantile, probs = 0.5, names = FALSE)
ppc3 <- apply(yPPCExp, 1, IQR)
ppc <- tibble(
    `Prop(hat(Y)<1.5)` = ppc1,
    `Median(hat(Y))` = ppc2,
    `IQR(hat(Y))` = ppc3,
    model = "O2"
)
yPPCN <- extract(m0N, "y_ppc")$y_ppc
yPPCNExp <- exp(yPPCN)
ppc1 <- rowMeans(yPPCN < log(1.5))
ppc2 <- apply(yPPCNExp, 1, quantile, probs = 0.5, names = FALSE)
ppc3 <- apply(yPPCNExp, 1, IQR)
ppcN <- tibble(
    `Prop(hat(Y)<1.5)` = ppc1,
    `Median(hat(Y))` = ppc2,
    `IQR(hat(Y))` = ppc3,
    model = "O1"
)
allPPC <- bind_rows(ppc, ppcN) %>%
    gather(ppc, value, -model)
## Observed data
biofouling <- readRDS("../data/biofouling.rds")
obs <- tibble(ppc = c("Prop(hat(Y)<1.5)", "Median(hat(Y))", "IQR(hat(Y))"),
              value = with(biofouling,
                           c(mean(wetWeight < 1.5), median(wetWeight),
                             IQR(wetWeight))))
plPPC <- ggplot(allPPC, aes(x = value)) +
    geom_histogram() +
    facet_grid(model ~ ppc, scales = "free", labeller = label_parsed) +
    geom_vline(aes(xintercept = value), data = obs) +
    xlab("") +
    ylab("Count") +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank())
plPPC

```

It appears here that the $t$ model reproduces the lower values better than the normal version.

## M1

The next model fit (M1) included all vessel-level predictors as main effects in a regression on the vessel-level intercept:

$$
\begin{align}
  \alpha_{j} & \sim \text{cauchy}(\alpha^{*}_{j}, \sigma_{\alpha}) \\
  \alpha^{*}_{j} & = \beta^{d1} \cdot \text{days1}_{j} + \beta^{d2} \cdot  \text{days2}_{j} + \beta^{m} \cdot \text{midTrips}_{j} + \beta^{h} \cdot \text{hullSA}_{j} + \beta_{p[j]} + \beta_{t[j]}
\end{align}
$$

where $\text{days1}_{j}$ is the number of days since vessel $j$ was last used; $\text{days2}_{j}$ is the number of days since the vessel was last cleaned; $\text{midTrips}_{j}$ is the median number of trips undertaken by the vessel per year; and $\text{hullSA}_{j}$ is the hull surface area. $\beta_{p[j]}$ is the effect of paint type $p$: ablative, hard or self-polishing anti-fouling paint; and $\beta_{t[j]}$ is the effect of vessel type: motor cruiser/other, fishing vessel or a yacht. Summary output from this model is given below.

### M1 &mdash; Normal distribution

```{r m1N,cache=TRUE}
m1N <- readRDS("../data/censored-mle-m1-var-bayes.rds")
m1Nll <- extract_log_lik(m1N)
m1Nloo <- loo::loo(m1Nll)
print(m1N, digits = 2, include = FALSE,
      par = c("alphaBoat", "muHat", "muHatCens", "log_lik", "alphaHat",
              "y_ppc", "y_lower"))

```

### M1 &mdash; $t$ distribution

```{r m1,cache=TRUE}
m1 <- readRDS("../data/censored-mle-m1-t-var-bayes.rds")
m1ll <- extract_log_lik(m1)
m1loo <- loo::loo(m1ll)
print(m1, digits = 2, include = FALSE,
      par = c("alphaBoat", "muHat", "muHatCens", "log_lik", "alphaHat",
              "y_ppc", "y_lower"))

```

### Comparison between Normal and $t$ assumptions

We now compare the two base models based on their predictive log-likelihoods:

```{r compare-m1}
compare(m1Nloo, m1loo)

```

So in the M1 models, there is now a difference in predictive log-likelihood between the Normal and $t$ distribution regressions, with the $t$ distribution being preferred.

### Posterior predictive checks

```{r post-pred-m1,cache=TRUE}
yPPC <- extract(m1, "y_ppc")$y_ppc
yPPCExp <- exp(yPPC)
ppc1 <- rowMeans(yPPC < log(1.5))
ppc2 <- apply(yPPCExp, 1, quantile, probs = 0.5, names = FALSE)
ppc3 <- apply(yPPCExp, 1, IQR)
ppc <- tibble(
    `Prop(hat(Y)<1.5)` = ppc1,
    `Median(hat(Y))` = ppc2,
    `IQR(hat(Y))` = ppc3,
    model = "O2"
)
yPPCN <- extract(m1N, "y_ppc")$y_ppc
yPPCNExp <- exp(yPPCN)
ppc1 <- rowMeans(yPPCN < log(1.5))
ppc2 <- apply(yPPCNExp, 1, quantile, probs = 0.5, names = FALSE)
ppc3 <- apply(yPPCNExp, 1, IQR)
ppcN <- tibble(
    `Prop(hat(Y)<1.5)` = ppc1,
    `Median(hat(Y))` = ppc2,
    `IQR(hat(Y))` = ppc3,
    model = "O1"
)
allPPC <- bind_rows(ppc, ppcN) %>%
    gather(ppc, value, -model)
plPPC <- ggplot(allPPC, aes(x = value)) +
    geom_histogram() +
    facet_grid(model ~ ppc, scales = "free", labeller = label_parsed) +
    geom_vline(aes(xintercept = value), data = obs) +
    xlab("") +
    ylab("Count") +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank())
plPPC

```

It appears here that the $t$ model reproduces the lower values better than the normal version.

# Vessel-level intercept interrogation

In this section we look at the estimated vessel-level intercepts ($\alpha_{j}$) in relation to the vessel-level predictors. From the output above, it is hard to gauge the impact of a product term, but the size of the 50% point estimate of the vessel type coefficients suggest that they may be candidates.

## Candidate interaction terms

The figure below shows the 50% point estimate (and 80% credible intervals) of the vessel-level intercept against the ordinal predictors, coloured by the vessel type; the regression line is at the base category of motor cruiser/other. There is a possibility of an interaction between `days1`/`midTrips` and `boatType`.

```{r}
bLookup <- readRDS("../data/biofouling.rds") %>%
    select(boatType, paintType, boatTypeInt, paintTypeInt) %>%
    distinct() %>%
    na.omit()
a1 <- extract(m1, "alphaBoat")$alphaBoat
a1Sum <- t(apply(a1, 2, quantile, probs = c(0.1, 0.5, 0.9)))
a1Dat <- tibble(low = a1Sum[,1], mid = a1Sum[,2], high = a1Sum[,3],
                boatID = 1:nrow(a1Sum))
imps <- readRDS("../data/imputations.rds")
set.seed(13)
lvl2 <- imps[[sample(seq_along(imps), 1)]]$lvl2 %>%
    left_join(., bLookup, by = c("boatTypeInt", "paintTypeInt")) %>%
    select(-paintTypeInt, -boatTypeInt)
a1Dat <- left_join(a1Dat, lvl2, by = "boatID") %>%
    gather(type, value, -low, -mid, -high, -boatID, -paintType, -boatType)
slopes <- extract(m1, c("betaDays1", "betaDays2", "betaMidTrips",
                        "betaHullSA"))
slopes <- sapply(slopes, quantile, probs = 0.5)
ints <- extract(m1, "betaType")$betaType
ints <- apply(ints, 2, quantile, probs = 0.5)
coefs <- tibble(slope = rep(slopes, 3),
                type = rep(unique(a1Dat$type), 3),
                intercept = rep(ints, each = 4),
                boatTypeInt = rep(1:3, each = 4)) %>%
    left_join(., bLookup %>% select(contains("boat")) %>% distinct(),
              by = "boatTypeInt")
pl <- ggplot(a1Dat, aes(x = value, y = mid, ymin = low, ymax = high,
                        colour = boatType)) +
    geom_pointrange(fatten = 1) +
    facet_wrap(~ type) +
    geom_abline(aes(slope = slope, intercept = intercept,
                    colour = boatType), data = coefs) +
    theme_bw()
print(pl)

```

The next figure is similar to above, but it shows the points coloured by paint type. This plot is suggestive of an interaction between `midTrips` and `paintType`.

```{r}
ints <- extract(m1, "betaPaint")$betaPaint
ints <- apply(ints, 2, quantile, probs = 0.5)
coefs <- tibble(slope = rep(slopes, 3),
                type = rep(unique(a1Dat$type), 3),
                intercept = rep(ints, each = 4),
                paintTypeInt = rep(1:3, each = 4)) %>%
    left_join(., bLookup %>% select(contains("paint")) %>% distinct(),
              by = "paintTypeInt")
pl <- ggplot(a1Dat, aes(x = value, y = mid, ymin = low, ymax = high,
                        colour = paintType)) +
    geom_pointrange(fatten = 1) +
    facet_wrap(~ type) +
    geom_abline(aes(slope = slope, intercept = intercept,
                    colour = paintType), data = coefs) +
    theme_bw() +
    theme(legend.position = "bottom")
print(pl)

```

So combining these two exploratory data analyses, and the results from M1, a possible sequence of models to try next would be: M2, which removes `hullSA` from M1; and M3 which adds the `days1:boatType`, `midTrips:boatType` and `midTrips:paintType` interactions to M2.

## Interrogation of product terms

The choice of predictors in M2 was made based on the candidate interaction terms in M3. Removing `hullSA` from M1 resulted in the following estimates for M2:

```{r m2,cache=TRUE}
m2 <- readRDS("../data/censored-mle-m2-t-var-bayes.rds")
m2ll <- extract_log_lik(m2)
m2loo <- loo::loo(m2ll)
m2comp <- compare(m1loo, m2loo)
print(m2, digits = 2, include = FALSE,
      par = c("alphaBoat", "muHat", "muHatCens", "log_lik", "alphaHat",
              "y_ppc", "y_lower"))

```

As can be seen in these estimates, there is virtually no change in values from that in M1. Further, the difference in the expected log predictive density between the two models is very small: `r m2comp[1]` (`r m2comp[2]`), providing further evidence the two models are essentially the same.

Moving on to M3, where the interactions `days1:boatType`, `midTrips:boatType` and `midTrips:paintType` are added to M2, we get the following estimates:

```{r m3,cache=TRUE}
m3 <- readRDS("../data/censored-mle-m3-t-var-bayes.rds")
m3ll <- extract_log_lik(m3)
m3loo <- loo::loo(m3ll)
print(m3, digits = 2, include = FALSE,
      par = c("alphaBoat", "muHat", "muHatCens", "log_lik", "alphaHat",
              "y_ppc", "y_lower"))

```

Again, there is not enough evidence to state with any certainty how these interactions might affect the wet weight biomass. It is important to remember that there are only `r nrow(lvl2)` vessels contributing to the regression at the second-level, so we do not expect very small standard errors for these estimates.

```{r}
a3 <- extract(m3, "alphaBoat")$alphaBoat
a3Sum <- t(apply(a3, 2, quantile, probs = c(0.1, 0.5, 0.9)))
a3Dat <- tibble(low = a3Sum[,1], mid = a3Sum[,2], high = a3Sum[,3],
                boatID = 1:nrow(a3Sum))
a3Dat <- left_join(a3Dat, lvl2) %>%
    select(-ApproxHullSA, -days2) %>%
    gather(type, value, -low, -mid, -high, -boatID, -paintType, -boatType)
slopes <- extract(m3, c("betaDays1", "betaDays2", "betaMidTrips",
                        "betaPaint", "betaType", "betaDaysType",
                        "betaTripsType", "betaTripsPaint"))
intType <- apply(slopes$betaType, 2, median)
slopeDaysType <- c(median(slopes$betaDays1 + slopes$betaDaysType[,1]),
                   median(slopes$betaDays1 + slopes$betaDaysType[,2]),
                   median(slopes$betaDays1 + slopes$betaDaysType[,3]))
slopeTripsType <- c(median(slopes$betaMidTrips + slopes$betaTripsType[,1]),
                    median(slopes$betaMidTrips + slopes$betaTripsType[,2]),
                    median(slopes$betaMidTrips + slopes$betaTripsType[,3]))
parsType <- tibble(intercept = rep(intType, 2),
                   slope = c(slopeDaysType, slopeTripsType),
                   boatTypeInt = rep(1:3, 2),
                   type = rep(c("days1", "midTrips"), each = 3)) %>%
    left_join(., bLookup %>% select(contains("boat")) %>% distinct(),
              by = "boatTypeInt")
pl <- ggplot(a3Dat, aes(x = value, y = mid, ymin = low, ymax = high,
                        colour = boatType)) +
    geom_pointrange(fatten = 1) +
    facet_wrap(~ type, ncol = 2) +
    geom_abline(aes(slope = slope, intercept = intercept, colour = boatType),
                data = parsType) +    
    theme_bw() +
    theme(legend.position = "bottom")
print(pl)

```

The figure above plots the marginal regression lines for the `days1:boatType` and `midTrips:boatType` interactions. There appears to be a difference in slopes in the `days1:boatType` interaction; indeed the posterior probability that the difference in slopes between Yachts and Motor cruiser/Other is greater than 0 is `r mean(slopes$betaDaysType[,3] - slopes$betaDaysType[,1] > 0)`. Similarly for `midTrips:boatType`.

The figure below plots the marginal regression line for the `midTrips:paintType` interaction. Again, there appears to be an interaction.

```{r}
intPaint <- apply(slopes$betaPaint, 2, median)
slopeTripsPaint <- c(median(slopes$betaMidTrips + slopes$betaTripsPaint[,1]),
                     median(slopes$betaMidTrips + slopes$betaTripsPaint[,2]),
                     median(slopes$betaMidTrips + slopes$betaTripsPaint[,3]))
parsType <- tibble(intercept = intPaint,
                   slope = slopeTripsPaint,
                   paintTypeInt = 1:3,
                   type = rep("midTrips", each = 3)) %>%
    left_join(., bLookup %>% select(contains("paint")) %>% distinct(),
              by = "paintTypeInt")
pl <- ggplot(a3Dat %>% filter(type == "midTrips"),
             aes(x = value, y = mid, ymin = low, ymax = high,
                 colour = paintType)) +
    geom_pointrange(fatten = 1) +
    geom_abline(aes(slope = slope, intercept = intercept, colour = paintType),
                data = parsType) +    
    theme_bw() +
    theme(legend.position = "bottom")
print(pl)

```

## Model Choice

In terms of model choice, a comparison between all models is shown below:

```{r model-choice}
compare(m0, m1, m2, m3)

```

Clearly, M3 is the best performing model.

# Outdated

This section is now outdated (2017-10-09); the candidate predictors for interactions above look reasonably good, and fit in with theory, so we'll stop here.

## Restricted model form

I think the appropriate place to go now is to eliminate terms that don't appear to add any predictive ability to the model. We'll keep the `days1:boatType` interaction (and its components), but remove other predictors. Model M4, will thus have a vessel-level regression form:

$$
\begin{align}
  \alpha^{*}_{j} & = \beta^{d1} \cdot \text{days1}_{i} + \beta^{d2} \cdot  \text{days2}_{i} + \beta^{t1} \cdot \text{vesselType1}_{i} + \beta^{t2} \cdot \text{vesselType2}_{i} + \\
  & \quad \beta^{dt1} \cdot \text{days1vesselType1}_{i} + \beta^{dt2} \cdot \text{days1vesselType2}_{i}
\end{align}
$$

where $\text{days1vesselType1}_{i},\text{days1vesselType2}_{i}$ are the interaction terms.

The output below provides a summary of the estimates from M4, with the figure showing the marginal effects of the `days1:boatType` interaction, and the `days2` marginal effect (adjusted for vessel type in the plot).

```{r m4,cache=TRUE,eval=FALSE}
m4 <- readRDS("../data/censored-mle-m4-t-var-bayes.rds")
m4ll <- extract_log_lik(m4)
m4loo <- loo::loo(m4ll)
print(m4, digits = 2, include = FALSE,
      par = c("alphaBoat", "muHat", "muHatCens", "log_lik", "alphaHat",
              "y_ppc", "y_lower"))

```

```{r,eval=FALSE}
a4 <- extract(m4, "alphaBoat")$alphaBoat
a4Sum <- t(apply(a4, 2, quantile, probs = c(0.1, 0.5, 0.9)))
a4Dat <- tibble(low = a4Sum[,1], mid = a4Sum[,2], high = a4Sum[,3],
                boatID = 1:nrow(a4Sum))
a4Dat <- left_join(a4Dat, lvl2) %>%
    select(-ApproxHullSA, -midTrips) %>%
    gather(type, value, -low, -mid, -high, -boatID, -paintType, -boatType)
slopes <- extract(m4, c("mu", "betaDays1", "betaDays2", "betaType",
                        "betaDaysType"))
intType <- c(0, median(slopes$betaType[,1]), median(slopes$betaType[,2]))
slopeDaysType <- c(median(slopes$betaDays1),
                   median(slopes$betaDays1 + slopes$betaDaysType[,1]),
                   median(slopes$betaDays1 + slopes$betaDaysType[,2]))
parsType <- tibble(intercept = intType, slope = slopeDaysType,
                   boatType = factor(levels(a4Dat$boatType)),
                   type = rep("days1", 3))
pl <- ggplot(a4Dat %>% filter(type == "days1"),
             aes(x = value, y = mid, ymin = low, ymax = high,
                 colour = boatType)) +
    geom_pointrange(fatten = 1) +
    geom_abline(aes(slope = slope, intercept = intercept, colour = boatType),
                data = parsType) +    
    theme_bw() +
    theme(legend.position = "bottom")
pl2 <- ggplot(a4Dat %>% filter(type == "days2"),
              aes(x = value, y = mid, ymin = low, ymax = high,
                  colour = boatType)) +
    geom_pointrange(fatten = 1) +
    geom_abline(aes(slope = median(slopes$betaDays2), intercept = intercept,
                    colour = boatType), data = parsType) +
    theme_bw() +
    theme(legend.position = "bottom")

print(pl)

```

```{r,eval=FALSE}
nC <- sum(biofouling$boatID %in% which(a4Sum[,2] < -5))

```

As in all model output previously, there are some large (negative) effects estimated for the vessel-level intercepts of three vessels. These vessels had a total of `nC` wet weight biomass measurements taken, all of them under the limit of detection. The model appears to be doing a good job at estimating this in the vessel-level intercepts.

<p>
  <br><br><br>
  All views presented within are the author's only, and do not necessarily represent the views of CEBRA.
  <br><br>
</p>
